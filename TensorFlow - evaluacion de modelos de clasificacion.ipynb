{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASO DE CLASIFICACION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# se definen los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.concatenate((np.random.normal(loc=-2, scale=1, size=100), np.random.normal(loc=2, scale=1, size=100)) ) ## 200 valores aleatorios, los 100 primeros con media=-2 y desviacion=1; y los 100 siguientes con media=2 y desviacion=1 \n",
    "y_vals = np.concatenate((np.repeat(0.,100), np.repeat(1.,100))) ##200 valores para el target, los 100 primeros con valor 0, ylos 100 siguientes con valor 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# se define el batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# se definen los placeholders y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(shape=[1,None], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[1,None], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# se dividen los datos originales en entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = np.random.choice(len(x_vals), size=round(len(x_vals)*0.8), replace=False) ## se escogen una cantidad de indices que corresponde al 80% de los datos del dataset para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 39,  13,  49,  69, 109, 195,  78,  85, 187,  16, 169,  90, 147,\n",
       "        67,  27,  86,  58,  38,  89,  97,  47, 179, 141,  88, 192, 130,\n",
       "       186, 126, 135, 158, 185,  76, 139, 145, 191,   9,  48, 162, 118,\n",
       "        79, 152,  25, 136, 163, 153,  68,  60,  72, 149,  91,  62,  54,\n",
       "       154,  63, 188, 103,  28,  43, 108,  37, 167, 151,  32,  10,  17,\n",
       "       182,  41, 159,  45,  18,  56,  26,  71,  31, 168, 156,  93, 146,\n",
       "        95,  21, 171, 196, 142, 112, 132, 174, 120, 110,  83, 134,  77,\n",
       "        64, 148, 183,  75,  57,  55,  87,  65, 197,  46, 172, 123, 150,\n",
       "        34, 157, 117, 105,  82, 115, 199, 113,  36,   1, 178, 122,  50,\n",
       "        61,  96,  53,  59, 165, 129, 128, 114, 131,   5,  19, 193,   8,\n",
       "       177,  66,  33,  44, 184,  74, 143,  98, 102, 116, 133,  81, 176,\n",
       "       198, 111,   7, 166,   3, 173, 155,  73, 170,  12, 180, 161, 175,\n",
       "       104, 164, 101,  52])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = np.array(list(set(range(len(x_vals)))-set(train_index))) ## se escogen una cantidad de indices que corresponde al 20% de los datos del dataset para test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   2,   4,   6, 137, 138,  11, 140,  14,  15, 144,  20,  22,\n",
       "        23,  24,  29,  30, 160,  35,  40,  42,  51, 181, 189, 190, 194,\n",
       "        70,  80,  84,  92,  94,  99, 100, 106, 107, 119, 121, 124, 125,\n",
       "       127])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals_train = x_vals[train_index]\n",
    "y_vals_train = y_vals[train_index]\n",
    "\n",
    "x_vals_test = x_vals[test_index]\n",
    "y_vals_test = y_vals[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# se definen las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.Variable(tf.random_normal(mean=10, shape=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# se crea el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_prediction = tf.add(x_data, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# se inicializan las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# se define la funcion de perdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=my_prediction, labels=y_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# se define el optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizador = tf.train.GradientDescentOptimizer(learning_rate=0.05)\n",
    "train_step = optimizador.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# se entrena el modelo( solo con los datos del conjunto de entrenamiento, que es el 80% del dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paso: 100A= [8.515031]loss= 3.4975104\n",
      "paso: 200A= [6.0756335]loss= 1.9694046\n",
      "paso: 300A= [3.856377]loss= 1.497083\n",
      "paso: 400A= [2.209479]loss= 0.40549278\n",
      "paso: 500A= [1.1991411]loss= 0.16099446\n",
      "paso: 600A= [0.645656]loss= 0.23342884\n",
      "paso: 700A= [0.3496855]loss= 0.13657576\n",
      "paso: 800A= [0.17051691]loss= 0.21798801\n",
      "paso: 900A= [0.07839961]loss= 0.16158949\n",
      "paso: 1000A= [0.05281516]loss= 0.19448714\n",
      "paso: 1100A= [0.01639732]loss= 0.15275756\n",
      "paso: 1200A= [0.01609104]loss= 0.19010447\n",
      "paso: 1300A= [0.0231944]loss= 0.14629479\n",
      "paso: 1400A= [0.0195934]loss= 0.1699996\n",
      "paso: 1500A= [-0.01074644]loss= 0.19410983\n",
      "paso: 1600A= [-0.00878871]loss= 0.21014413\n",
      "paso: 1700A= [-0.00022747]loss= 0.17717227\n",
      "paso: 1800A= [-0.00187216]loss= 0.19671778\n",
      "paso: 1900A= [-0.01702935]loss= 0.23398139\n",
      "paso: 2000A= [-0.01944813]loss= 0.2362204\n"
     ]
    }
   ],
   "source": [
    "for i in range(2000):\n",
    "    rand_index = np.random.choice(len(x_vals_train), size=batch_size) ##se elige una cantidad de indces del tama√±o del \"batch_size\", solo del conjunto de entrenamiento\n",
    "    rand_x = [x_vals_train[rand_index]] ##datos de entrenamiento de entrada\n",
    "    rand_y = [y_vals_train[rand_index]] ##targets de entrenamiento\n",
    "    session.run(train_step, feed_dict={x_data:rand_x, y_target:rand_y})\n",
    "    if(i+1)%100==0:\n",
    "        print(\"paso: \"+str(i+1)+ \"A= \"+str(session.run(A))+ \"loss= \"+str(session.run(loss, feed_dict={x_data:rand_x, y_target:rand_y})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluacion del modelo con la precision(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## funcion de accuracy\n",
    "y_prediction = tf.squeeze(tf.round(tf.nn.sigmoid(my_prediction))) ##la funcion \"squeeze\" aplana los datos de la prediccion para que quede en forma de vector\n",
    "correct_prediction = tf.equal(y_prediction, y_target) ##vector de verdaderos(V) y falsos(F)r\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) ##la funcion \"cast\" transforma los V en unos y los F en ceros; luego con la funcion \"reduce_mean\" se saca el promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision en el conjunto de entrenamiento: 0.9875\n"
     ]
    }
   ],
   "source": [
    "acc_train = session.run(accuracy, feed_dict={x_data:[x_vals_train], y_target:[y_vals_train]}) \n",
    "print(\"precision en el conjunto de entrenamiento: \" +str(acc_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision en el conjunto de test: 0.95\n"
     ]
    }
   ],
   "source": [
    "acc_test = session.run(accuracy, feed_dict={x_data:[x_vals_test], y_target:[y_vals_test]})\n",
    "print(\"precision en el conjunto de test: \" +str(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
